{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"Train a simple convnet on the MNISt dataset.\n",
        "\n",
        "Only the first layer has quantization annotation and quantized trained. A\n",
        "representative dataset is set to invoke the post-training quantization as well.\n",
        "The model should be fully quantized at the end.\n",
        "\"\"\"\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf  # pylint: disable=g-bad-import-order\n",
        "\n",
        "from tensorflow_model_optimization.python.core.quantization.keras import quantize\n",
        "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "if keras.backend.image_data_format() == 'channels_first':\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "  input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "  input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "batch_input_shape = (1,) + input_shape\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "l = keras.layers\n",
        "\n",
        "keras_file = '/tmp/quantized_mnist.h5'\n",
        "if not os.path.exists(keras_file):\n",
        "  model = keras.Sequential([\n",
        "      # Only the fisrt layer is quantized trained.\n",
        "      # The rest of the layers are not quantization-aware.\n",
        "      quantize.quantize_annotate_layer(\n",
        "          l.Conv2D(\n",
        "              32, 5, padding='same', activation='relu', input_shape=input_shape\n",
        "          )\n",
        "      ),\n",
        "      l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "      l.Conv2D(64, 5, padding='same', activation='relu'),\n",
        "      l.BatchNormalization(),\n",
        "      l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "      l.Flatten(),\n",
        "      l.Dense(1024, activation='relu'),\n",
        "      l.Dropout(0.4),\n",
        "      l.Dense(num_classes),\n",
        "      l.Softmax(),\n",
        "  ])\n",
        "  model = quantize.quantize_apply(model)\n",
        "  model.compile(\n",
        "      loss=keras.losses.categorical_crossentropy,\n",
        "      optimizer=keras.optimizers.Adadelta(),\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "  model.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      verbose=1,\n",
        "      validation_data=(x_test, y_test))\n",
        "\n",
        "  # Export to Keras.\n",
        "  keras.models.save_model(model, keras_file)\n",
        "\n",
        "with quantize.quantize_scope():\n",
        "  model = keras.models.load_model(keras_file)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "# Use the first 300 images in the post-training quantization.\n",
        "def calibration_gen():\n",
        "  for i in range(3000):\n",
        "    image = x_train[i].reshape(batch_input_shape)\n",
        "    yield [image]\n",
        "\n",
        "# Convert to TFLite model.\n",
        "with quantize.quantize_scope():\n",
        "  # It is complex to set the flags with converter v1:\n",
        "  #\n",
        "  #  converter = tf.lite.TFLiteConverter.from_keras_model_file(\n",
        "  #      keras_file, input_shapes={'quant_conv2d_input': batch_input_shape})\n",
        "  #\n",
        "  # Must set the inference_input_type to float, so we can still use the floating\n",
        "  # point training data. Set the inference_type to int8, to partially quantize\n",
        "  # the model.\n",
        "  # converter.inference_type = tf.lite.constants.INT8\n",
        "  # converter.inference_input_type = tf.lite.constants.FLOAT\n",
        "  # input_arrays = converter.get_input_arrays()\n",
        "  # print(input_arrays)\n",
        "  # converter.quantized_input_stats = {\n",
        "  #     input_arrays[0]: (-128., 255.)\n",
        "  # }  # mean, std_dev values for float [0, 1] quantized to [-128, 127]\n",
        "  # Set the representative dataset for post-training quantization.\n",
        "\n",
        "  model = keras.models.load_model(keras_file)\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "converter.representative_dataset = calibration_gen\n",
        "converter.experimental_new_quantizer = True\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8\n",
        "]  # to enable post-training quantization with the representative dataset\n",
        "\n",
        "print('Convert TFLite model.')\n",
        "tflite_model = converter.convert()\n",
        "print('Write TFLite model.')\n",
        "tflite_file = '/tmp/quantized_mnist.tflite'\n",
        "open(tflite_file, 'wb').write(tflite_model)\n",
        "\n",
        "# Evaluate the fully quantized model.\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_file)\n",
        "interpreter.allocate_tensors()\n",
        "input_index = interpreter.get_input_details()[0]['index']\n",
        "output_index = interpreter.get_output_details()[0]['index']\n",
        "\n",
        "total_seen = 0\n",
        "num_correct = 0\n",
        "\n",
        "# Testing the entire dataset is too slow. Verifying only 300 of 10k samples.\n",
        "print('Evaluate TFLite model.')\n",
        "x_test = x_test[0:3000, :]\n",
        "y_test = y_test[0:3000, :]\n",
        "for img, label in zip(x_test, y_test):\n",
        "  inp = img.reshape(batch_input_shape)\n",
        "  total_seen += 1\n",
        "  interpreter.set_tensor(input_index, inp)\n",
        "  interpreter.invoke()\n",
        "  predictions = interpreter.get_tensor(output_index)\n",
        "  if np.argmax(predictions) == np.argmax(label):\n",
        "    num_correct += 1\n",
        "\n",
        "quantized_score = float(num_correct) / float(total_seen)\n",
        "print('Quantized accuracy:', quantized_score)\n",
        "\n",
        "# Ensure accuracy for quantized TF and TFLite models are similar to original\n",
        "# model. There is no clear way to measure quantization, but for MNIST\n",
        "# results which differ a lot likely suggest an error in quantization.\n",
        "np.testing.assert_allclose(score[1], quantized_score, rtol=0.2, atol=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thkTbLzzovH0",
        "outputId": "c632da7f-b433-406b-f4c2-f66cc47b01fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.9521\n",
            "Test loss: 0.1736990064382553\n",
            "Test accuracy: 0.9520999789237976\n",
            "Convert TFLite model.\n",
            "Write TFLite model.\n",
            "Evaluate TFLite model.\n",
            "Quantized accuracy: 0.933\n"
          ]
        }
      ]
    }
  ]
}